{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRqjxHx-wNgf"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers faiss-cpu google-generativeai pandas numpy scikit-learn matplotlib seaborn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import warnings\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import google.generativeai as genai\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "GXCCFwTmwXH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'similarity_threshold': 0.8,\n",
        "    'fallback_threshold': 0.6,\n",
        "    'embedding_model': 'all-MiniLM-L6-v2',\n",
        "    'gemini_model': 'gemini-2.0-flash',\n",
        "    'gemini_api_key': '',\n",
        "}\n",
        "\n",
        "embedding_model = SentenceTransformer(CONFIG['embedding_model'])\n",
        "\n",
        "genai.configure(api_key=CONFIG['gemini_api_key'])\n",
        "gemini_model = genai.GenerativeModel(CONFIG['gemini_model'])"
      ],
      "metadata": {
        "id": "5f_vsh0jbSM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FAQDatabase:\n",
        "    def __init__(self):\n",
        "        self.faq_data = {}\n",
        "\n",
        "    def add_faq(self, asin: str, faq_entry):\n",
        "        if asin not in self.faq_data:\n",
        "            self.faq_data[asin] = []\n",
        "        self.faq_data[asin].append(faq_entry)\n",
        "\n",
        "    def get_faqs(self, asin: str):\n",
        "        return self.faq_data.get(asin, [])\n",
        "\n",
        "    def update_usage(self, asin: str, question):\n",
        "        if asin in self.faq_data:\n",
        "            for faq in self.faq_data[asin]:\n",
        "                if faq['question'] == question:\n",
        "                    faq['usage_count'] += 1\n",
        "                    break\n",
        "\n",
        "    def get_total_faqs(self):\n",
        "        return sum(len(faqs) for faqs in self.faq_data.values())\n",
        "\n",
        "    def get_products_count(self):\n",
        "        return len(self.faq_data)"
      ],
      "metadata": {
        "id": "20V1ZZ0Yroc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_products = \"amazon_products.csv\"\n",
        "products_df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"asaniczka/amazon-products-dataset-2023-1-4m-products\",\n",
        "    file_path_products\n",
        ")\n",
        "\n",
        "file_path_categories = \"amazon_categories.csv\"\n",
        "categories_df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"asaniczka/amazon-products-dataset-2023-1-4m-products\",\n",
        "    file_path_categories\n",
        ")\n",
        "\n",
        "print(\"Products shape:\", products_df.shape)\n",
        "print(\"Categories shape:\", categories_df.shape)"
      ],
      "metadata": {
        "id": "zLWFwvs5waT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_df.info()"
      ],
      "metadata": {
        "id": "T5C4M3m0TP2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories_df.info()"
      ],
      "metadata": {
        "id": "SRMym6gbqYZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_df = products_df.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "WWOZ4yCiekv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_df['asin'] = products_df['asin'].astype(str)"
      ],
      "metadata": {
        "id": "ZKOFrQwSpElp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_single = \"single_qna.csv\"\n",
        "qna_df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"praneshmukhopadhyay/amazon-questionanswer-dataset\",\n",
        "    file_path_single\n",
        ")\n",
        "\n",
        "print(\"Single QnA shape:\", qna_df.shape)"
      ],
      "metadata": {
        "id": "sl7zBbABwjaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qna_df.info()"
      ],
      "metadata": {
        "id": "MZmw57iwTdIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qna_df = qna_df[['Asin', 'Question', 'Answer']].copy()\n",
        "qna_df.rename(columns={'Asin': 'asin'}, inplace=True)"
      ],
      "metadata": {
        "id": "pDM3u6ErYkE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qna_df['asin'] = qna_df['asin'].astype(str)\n",
        "qna_df = qna_df.dropna().reset_index(drop=True)\n",
        "qna_df = qna_df.drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "qhoZannupIfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = qna_df.merge(products_df, on='asin', how='inner')"
      ],
      "metadata": {
        "id": "ZyIVXBERpMc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "id": "ke-N3AUqqPzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.merge(\n",
        "    categories_df.rename(columns={'id': 'category_id'}),\n",
        "    on='category_id',\n",
        "    how='left'\n",
        ")\n",
        "merged_df.drop(columns=['category_id', 'boughtInLastMonth'], inplace=True)\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "NvZ6_lZIZyaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "id": "fPVeaqVzrZrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StandardizedFAQEntry:\n",
        "    def __init__(self, question, answer, asin: str, confidence=1.0):\n",
        "        self.question = question\n",
        "        self.answer = answer\n",
        "        self.processed_question = self.preprocess_text(question)\n",
        "        self.processed_answer = self.preprocess_text(answer)\n",
        "        self.asin = asin\n",
        "        self.confidence = confidence\n",
        "        self.created_at = datetime.now().isoformat()\n",
        "        self.usage_count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_text(text):\n",
        "        stopwords_set = {\"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"on\", \"at\", \"to\", \"for\", \"of\", \"with\", \"by\"}\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"<.*?>\", \" \", text)\n",
        "        text = re.sub(r\"[^a-z0-9$%.,!?'\\\\s]\", \" \", text)\n",
        "        text = re.sub(r\"\\\\s+\", \" \", text)\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords_set]\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'question': self.question,\n",
        "            'answer': self.answer,\n",
        "            'processed_question': self.processed_question,\n",
        "            'processed_answer': self.processed_answer,\n",
        "            'asin': self.asin,\n",
        "            'confidence': self.confidence,\n",
        "            'created_at': self.created_at,\n",
        "            'usage_count': self.usage_count\n",
        "        }"
      ],
      "metadata": {
        "id": "gsOL3maDs97x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_set = {\"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"on\", \"at\", \"to\", \"for\", \"of\", \"with\", \"by\"}\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<.*?>\", \" \", text)\n",
        "    text = re.sub(r\"[^a-z0-9$%.,!?'\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords_set]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "merged_df[\"Question_processed\"] = merged_df[\"Question\"].apply(preprocess_text)\n",
        "merged_df[\"Answer_processed\"]   = merged_df[\"Answer\"].apply(preprocess_text)\n",
        "merged_df[\"title_processed\"] = merged_df[\"title\"].apply(preprocess_text)\n",
        "merged_df[\"category_processed\"]   = merged_df[\"category_name\"].apply(preprocess_text)\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "32NPTjSyseUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = {}\n",
        "\n",
        "embeddings['questions'] = embedding_model.encode(merged_df['Question_processed'].tolist(), show_progress_bar=True)\n",
        "PRODUCT_EMBEDDINGS = embeddings\n",
        "\n",
        "embeddings['questions'].shape"
      ],
      "metadata": {
        "id": "23UX4EXSAooF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SemanticSearchEngine:\n",
        "    def __init__(self, embeddings, df):\n",
        "        self.embeddings = embeddings\n",
        "        self.df = df\n",
        "        self.index = faiss.IndexFlatIP(self.embeddings['questions'].shape[1])\n",
        "\n",
        "        normalized_embeddings = self.embeddings['questions'].copy()\n",
        "        faiss.normalize_L2(normalized_embeddings)\n",
        "        self.index.add(normalized_embeddings)\n",
        "\n",
        "    def search_similar_questions(self, query, top_k=5, similarity_threshold=0.5):\n",
        "        processed_query = StandardizedFAQEntry.preprocess_text(query)\n",
        "        query_embedding = embedding_model.encode([processed_query])\n",
        "\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "        similarities, indices = self.index.search(query_embedding, top_k)\n",
        "\n",
        "        results = []\n",
        "        for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):\n",
        "            if similarity >= similarity_threshold:\n",
        "                row = self.df.iloc[idx]\n",
        "                results.append({\n",
        "                    'similarity': float(similarity),\n",
        "                    'question': row['Question'],\n",
        "                    'answer': row['Answer'],\n",
        "                    'asin': row['asin'],\n",
        "                    'title': row['title'],\n",
        "                    'category': row['category_name'],\n",
        "                    'index': int(idx)\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def search_by_product(self, asin: str, query, top_k=3, fallback_threshold=0.5):\n",
        "        product_mask = self.df['asin'] == asin\n",
        "        if not product_mask.any():\n",
        "            return []\n",
        "\n",
        "        product_indices = self.df[product_mask].index.tolist()\n",
        "        product_embeddings = self.embeddings['questions'][product_indices]\n",
        "\n",
        "        temp_index = faiss.IndexFlatIP(product_embeddings.shape[1])\n",
        "        normalized_product_embeddings = product_embeddings.copy()\n",
        "        faiss.normalize_L2(normalized_product_embeddings)\n",
        "        temp_index.add(normalized_product_embeddings)\n",
        "\n",
        "        processed_query = StandardizedFAQEntry.preprocess_text(query)\n",
        "        query_embedding = embedding_model.encode([processed_query])\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        similarities, indices = temp_index.search(query_embedding, min(top_k, len(product_indices)))\n",
        "\n",
        "        results = []\n",
        "        for similarity, idx in zip(similarities[0], indices[0]):\n",
        "            if similarity >= fallback_threshold:\n",
        "                original_idx = product_indices[idx]\n",
        "                row = self.df.iloc[original_idx]\n",
        "                results.append({\n",
        "                    'similarity': float(similarity),\n",
        "                    'question': row['Question'],\n",
        "                    'answer': row['Answer'],\n",
        "                    'asin': row['asin'],\n",
        "                    'title': row['title'],\n",
        "                    'index': original_idx\n",
        "                })\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "zNyEY1J8nJHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryMonitor:\n",
        "    def __init__(self):\n",
        "        self.query_log = []\n",
        "\n",
        "    def log_query(self, query, asin: str):\n",
        "        query_entry = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'query': query,\n",
        "            'processed_query': StandardizedFAQEntry.preprocess_text(query),\n",
        "            'asin': asin,\n",
        "            'resolved': False,\n",
        "            'response': None\n",
        "        }\n",
        "\n",
        "        self.query_log.append(query_entry)\n",
        "        return len(self.query_log) - 1\n",
        "\n",
        "    def update_query_result(self, query_id: int, response: dict):\n",
        "        self.query_log[query_id]['response'] = response\n",
        "        self.query_log[query_id]['resolved'] = response.get('status') in ['resolved', 'generated']\n",
        "\n",
        "    def get_unresolved_queries(self):\n",
        "        return [q for q in self.query_log if not q.get('resolved', False)]\n",
        "\n",
        "    def get_query_stats(self):\n",
        "        total_queries = len(self.query_log)\n",
        "        if total_queries == 0:\n",
        "            return {'total_queries': 0, 'resolved': 0, 'resolution_rate': 0, 'unresolved_queries': 0}\n",
        "\n",
        "        resolved = sum(1 for q in self.query_log if q.get('resolved', False))\n",
        "\n",
        "        return {\n",
        "            'total_queries': total_queries,\n",
        "            'resolved': resolved,\n",
        "            'resolution_rate': resolved / total_queries,\n",
        "            'unresolved_queries': total_queries - resolved\n",
        "        }"
      ],
      "metadata": {
        "id": "09jWQ15uo4l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FAQGenerator:\n",
        "    def __init__(self, faq_database, gemini_model):\n",
        "        self.generation_history = []\n",
        "        self.gemini_model = gemini_model\n",
        "        self.faq_database = faq_database\n",
        "        self.search_engine = None\n",
        "\n",
        "    def set_search_engine(self, search_engine):\n",
        "        self.search_engine = search_engine\n",
        "\n",
        "    def generate_answer_with_gemini(self, question, product_info, similar_faqs):\n",
        "\n",
        "        context = self.prepare_context(similar_faqs)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a helpful e-commerce customer service AI assistant.\n",
        "Answer the customer's question based on the provided product information and similar FAQs.\n",
        "\n",
        "CUSTOMER QUESTION: {question}\n",
        "\n",
        "PRODUCT INFORMATION:\n",
        "- Product Name: {product_info.get('title', 'N/A')}\n",
        "- Category: {product_info.get('category_name', 'N/A')}\n",
        "- Price: ${product_info.get('price', 'N/A')}\n",
        "- Rating: {product_info.get('stars', 'N/A')} stars ({product_info.get('reviews', 0)} reviews)\n",
        "\n",
        "{context}\n",
        "\n",
        "GUIDELINES:\n",
        "1. Be helpful, accurate, and concise\n",
        "2. If you don't have specific information, say so clearly\n",
        "3. Keep the answer under 200 words\n",
        "4. Use a friendly, professional tone\n",
        "5. For unknown questions, advise contacting support\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            return response.text.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Gemini API error: {e}\")\n",
        "            return self.generate_fallback_answer(question, product_info, similar_faqs)\n",
        "\n",
        "    def prepare_context(self, similar_faqs):\n",
        "        context = \"\"\n",
        "\n",
        "        if similar_faqs and len(similar_faqs) > 0:\n",
        "            context = \"SIMILAR QUESTIONS AND ANSWERS:\\n\"\n",
        "            for i, faq in enumerate(similar_faqs[:3], 1):\n",
        "                context += f\"{i}. Q: {faq['question']}\\n\"\n",
        "                context += f\"   A: {faq['answer']}\\n\\n\"\n",
        "        return context\n",
        "\n",
        "    def generate_fallback_answer(self, question, product_info, similar_faqs):\n",
        "\n",
        "        if similar_faqs and len(similar_faqs) > 0:\n",
        "            best_match = similar_faqs[0]\n",
        "            return f\"Based on similar questions about this product: {best_match['answer']} (Note: This is from a similar question as our AI assistant is temporarily unavailable)\"\n",
        "\n",
        "        return f\"Thank you for your question about {product_info.get('title', 'this product')}. I'm currently unable to provide a specific answer, but I recommend checking the product page for detailed information or contacting our customer support team for personalized assistance.\"\n",
        "\n",
        "    def generate_answer_with_context(self, question, asin: str, df):\n",
        "\n",
        "        product_rows = df[df['asin'] == asin]\n",
        "\n",
        "        if product_rows.empty:\n",
        "            return {'error': 'Product not found', 'answer': 'Sorry, I could not find any information about this product.'}\n",
        "\n",
        "        product_row = product_rows.iloc[0]\n",
        "\n",
        "        product_info = {\n",
        "            'title': product_row['title'],\n",
        "            'category_name': product_row['category_name'],\n",
        "            'price': product_row.get('price'),\n",
        "            'stars': product_row.get('stars'),\n",
        "            'reviews': product_row.get('reviews', 0)\n",
        "        }\n",
        "\n",
        "        similar_faqs = self.search_engine.search_by_product(asin, question, top_k=3) if self.search_engine else []\n",
        "        answer = self.generate_answer_with_gemini(question, product_info, similar_faqs)\n",
        "\n",
        "        faq_entry = StandardizedFAQEntry(\n",
        "            question=question,\n",
        "            answer=answer,\n",
        "            asin=asin,\n",
        "            confidence=0.8 if similar_faqs else 0.5\n",
        "        )\n",
        "\n",
        "        self.faq_database.add_faq(asin, faq_entry.to_dict())\n",
        "\n",
        "        result = faq_entry.to_dict()\n",
        "        result.update({\n",
        "            'product_title': product_info['title'],\n",
        "            'generated_at': datetime.now().isoformat(),\n",
        "            'similar_faqs_count': len(similar_faqs)\n",
        "        })\n",
        "\n",
        "        self.generation_history.append(result)\n",
        "        return result"
      ],
      "metadata": {
        "id": "Hu2ANZ1KpQxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicFAQSystem:\n",
        "    def __init__(self, df, embeddings, faq_database, gemini_model):\n",
        "        self.df = df\n",
        "        self.embeddings = embeddings\n",
        "        self.faq_database = faq_database\n",
        "        self.search_engine = SemanticSearchEngine(embeddings, df)\n",
        "        self.query_monitor = QueryMonitor()\n",
        "        self.faq_generator = FAQGenerator(faq_database, gemini_model)\n",
        "        self.faq_generator.set_search_engine(self.search_engine)\n",
        "\n",
        "    def process_customer_query(self, query, asin: str):\n",
        "        query_id = self.query_monitor.log_query(query, asin)\n",
        "\n",
        "        similar_faqs = self.search_engine.search_by_product(asin, query, top_k=3, fallback_threshold=CONFIG['fallback_threshold'])\n",
        "        if not similar_faqs:\n",
        "            similar_faqs = self.search_engine.search_similar_questions(query, top_k=5, similarity_threshold=CONFIG['similarity_threshold'])\n",
        "\n",
        "        if similar_faqs:\n",
        "            product_rows = self.df[self.df['asin'] == asin]\n",
        "            if not product_rows.empty:\n",
        "                product_row = product_rows.iloc[0]\n",
        "                product_info = {\n",
        "                    'title': product_row['title'],\n",
        "                    'category_name': product_row['category_name'],\n",
        "                    'price': product_row.get('price'),\n",
        "                    'stars': product_row.get('stars'),\n",
        "                    'reviews': product_row.get('reviews', 0)\n",
        "                }\n",
        "            else:\n",
        "                product_info = {'title': 'Unknown Product', 'category_name': 'Unknown', 'price': 'N/A', 'stars': 'N/A', 'reviews': 0}\n",
        "\n",
        "            try:\n",
        "                answer = self.faq_generator.generate_answer_with_gemini(query, product_info, similar_faqs)\n",
        "\n",
        "                response = {\n",
        "                    'status': 'resolved',\n",
        "                    'method': 'gemini_processed',\n",
        "                    'question': query,\n",
        "                    'answer': answer,\n",
        "                    'confidence': similar_faqs[0]['similarity'],\n",
        "                    'source_asin': similar_faqs[0]['asin'],\n",
        "                    'similar_faqs': similar_faqs[:3],\n",
        "                    'processed_by_gemini': True\n",
        "                }\n",
        "\n",
        "                self.faq_database.update_usage(similar_faqs[0]['asin'], similar_faqs[0]['question'])\n",
        "\n",
        "            except Exception as e:\n",
        "                best_match = similar_faqs[0]\n",
        "                response = {\n",
        "                    'status': 'resolved',\n",
        "                    'method': 'existing_faq_fallback',\n",
        "                    'question': best_match['question'],\n",
        "                    'answer': best_match['answer'],\n",
        "                    'confidence': best_match['similarity'],\n",
        "                    'source_asin': best_match['asin'],\n",
        "                    'similar_faqs': similar_faqs[:3],\n",
        "                    'processed_by_gemini': False\n",
        "                }\n",
        "                self.faq_database.update_usage(best_match['asin'], best_match['question'])\n",
        "\n",
        "        else:\n",
        "            generated_faq = self.faq_generator.generate_answer_with_context(query, asin, self.df)\n",
        "            response = {\n",
        "                'status': 'generated',\n",
        "                'method': 'ai_generated',\n",
        "                'answer': generated_faq.get('answer'),\n",
        "                'confidence': generated_faq.get('confidence'),\n",
        "                'generated_faq': generated_faq\n",
        "            }\n",
        "\n",
        "        self.query_monitor.update_query_result(query_id, response)\n",
        "        return response\n",
        "\n",
        "    def get_system_stats(self):\n",
        "        return {\n",
        "            'query_stats': self.query_monitor.get_query_stats(),\n",
        "            'faq_database_size': self.faq_database.get_total_faqs(),\n",
        "            'products_with_faqs': self.faq_database.get_products_count(),\n",
        "            'generated_faqs': len(self.faq_generator.generation_history)\n",
        "        }"
      ],
      "metadata": {
        "id": "UPbxHwQGpfWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faq_db = FAQDatabase()\n",
        "faq_system = DynamicFAQSystem(merged_df, embeddings, faq_db, gemini_model)"
      ],
      "metadata": {
        "id": "TNnTAh5TGbZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_asins = merged_df['asin'].head(10).tolist()\n",
        "test_cases = [\n",
        "    {\n",
        "        'query': 'How long does shipping take?',\n",
        "        'asin': sample_asins[0],\n",
        "        'description': 'Common shipping question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'What is the warranty on this item?',\n",
        "        'asin': sample_asins[0],\n",
        "        'description': 'Warranty question (likely to need generation)'\n",
        "    },\n",
        "    {\n",
        "        'query': 'Is this product waterproof?',\n",
        "        'asin': sample_asins[1] if len(sample_asins) > 1 else sample_asins[0],\n",
        "        'description': 'Product feature question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'Can I return this if I don\\'t like it?',\n",
        "        'asin': sample_asins[1] if len(sample_asins) > 1 else sample_asins[0],\n",
        "        'description': 'Return policy question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'What colors are available?',\n",
        "        'asin': sample_asins[0],\n",
        "        'description': 'Product variation question'\n",
        "    },\n",
        "\n",
        "    # --- Less Usual but Valid Customer Questions ---\n",
        "    {\n",
        "        'query': 'Does it come with a user manual in Spanish?',\n",
        "        'asin': sample_asins[2] if len(sample_asins) > 2 else sample_asins[0],\n",
        "        'description': 'Language / documentation question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'Is it compatible with 220V power outlets?',\n",
        "        'asin': sample_asins[3] if len(sample_asins) > 3 else sample_asins[0],\n",
        "        'description': 'Compatibility with electrical standard'\n",
        "    },\n",
        "    {\n",
        "        'query': 'What materials is it made from?',\n",
        "        'asin': sample_asins[4] if len(sample_asins) > 4 else sample_asins[0],\n",
        "        'description': 'Material composition question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'How do I assemble it? Is any tool included?',\n",
        "        'asin': sample_asins[5] if len(sample_asins) > 5 else sample_asins[0],\n",
        "        'description': 'Assembly / tools question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'Can I schedule delivery for a specific date?',\n",
        "        'asin': sample_asins[6] if len(sample_asins) > 6 else sample_asins[0],\n",
        "        'description': 'Special delivery scheduling'\n",
        "    },\n",
        "    {\n",
        "        'query': 'asdasd asd 123 $$$',\n",
        "        'asin': sample_asins[1] if len(sample_asins) > 1 else sample_asins[0],\n",
        "        'description': 'Gibberish input'\n",
        "    },\n",
        "    {\n",
        "        'query': 'Who won the World Cup in 2018?',\n",
        "        'asin': sample_asins[0],\n",
        "        'description': 'Totally unrelated question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'What is the environmental impact of producing this item?',\n",
        "        'asin': sample_asins[3] if len(sample_asins) > 3 else sample_asins[0],\n",
        "        'description': 'Sustainability question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'Is this better than the previous model?',\n",
        "        'asin': sample_asins[5] if len(sample_asins) > 5 else sample_asins[0],\n",
        "        'description': 'Comparative product question'\n",
        "    },\n",
        "    {\n",
        "        'query': 'If I buy 3, can I get a discount?',\n",
        "        'asin': sample_asins[6] if len(sample_asins) > 6 else sample_asins[0],\n",
        "        'description': 'Bulk purchase discount inquiry'\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "HBcbIFyyG_4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for i, test_case in enumerate(test_cases, start=1):\n",
        "    print(f\"Test {i}: {test_case['description']}\")\n",
        "    print(f\"Query: '{test_case['query']}'\")\n",
        "    print(f\"Product ASIN: {test_case['asin']}\")\n",
        "\n",
        "    product_rows = merged_df[merged_df['asin'] == test_case['asin']]\n",
        "    if not product_rows.empty:\n",
        "        product_info = product_rows.iloc[0]\n",
        "        print(f\"Product: {product_info['title']}\")\n",
        "    else:\n",
        "        product_info = None\n",
        "        print(\"Product not found\")\n",
        "\n",
        "    try:\n",
        "        response = faq_system.process_customer_query(\n",
        "            test_case['query'],\n",
        "            test_case['asin']\n",
        "        )\n",
        "\n",
        "        print(f\"Status: {response['status'].upper()}\")\n",
        "        print(f\"Method: {response['method']}\")\n",
        "        print(f\"Confidence: {response.get('confidence', 0):.3f}\")\n",
        "\n",
        "        if response['status'] == 'resolved':\n",
        "            print(f\"Source ASIN: {response['source_asin']}\")\n",
        "\n",
        "        question = response.get('question', 'No question provided')\n",
        "        print(f\"Question: {question}\")\n",
        "        answer = response.get('answer', 'No answer provided')\n",
        "        print(f\"Answer: {answer}\")\n",
        "\n",
        "        results.append({\n",
        "            'test_case': test_case,\n",
        "            'response': response,\n",
        "            'success': True\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        results.append({\n",
        "            'test_case': test_case,\n",
        "            'response': None,\n",
        "            'success': False,\n",
        "            'error': str(e)\n",
        "        })\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "print(\"System Statistics:\")\n",
        "try:\n",
        "    stats = faq_system.get_system_stats()\n",
        "    print(f\"Total queries processed: {stats['query_stats']['total_queries']}\")\n",
        "    print(f\"Queries resolved: {stats['query_stats']['resolved']}\")\n",
        "    print(f\"Resolution rate: {stats['query_stats']['resolution_rate']:.2%}\")\n",
        "    print(f\"FAQ database size: {stats['faq_database_size']}\")\n",
        "    print(f\"Products with FAQs: {stats['products_with_faqs']}\")\n",
        "    print(f\"Generated FAQs: {stats['generated_faqs']}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "successful_tests = sum(1 for r in results if r['success'])\n",
        "print(\"\\nTest Summary:\")\n",
        "print(f\"Successful tests: {successful_tests}/{len(results)}\")\n",
        "if successful_tests < len(results):\n",
        "    print(f\"Failed tests: {len(results) - successful_tests}\")\n"
      ],
      "metadata": {
        "id": "mttZmYP_rPrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qjFyz1hCn4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}